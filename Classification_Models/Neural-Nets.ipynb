{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import imblearn\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from cross_validation import validation_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup_seed\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter for the NN\n",
    "Epochs = 20\n",
    "Lr_Rate = 1e-2\n",
    "Batch_Size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "file_name='../../Dataset_2.csv' \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# read data from csv file\n",
    "df = pd.read_csv(file_name)\n",
    "data=np.asarray(df.values.tolist())\n",
    "Y= np.asarray(data[:,0], dtype=np.float64)\n",
    "X= np.asarray(data[:,1:], dtype=np.float64)\n",
    "X=X.astype(np.float32)\n",
    "X_train, X_test, y_train,y_test= train_test_split(X, Y, test_size= 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the dataset\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        \"\"\"\n",
    "        Args: The data X and the label Y\n",
    "        \"\"\"\n",
    "        self.X= X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            print('yes')\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return  self.X[idx,:], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the vanilla dataset\n",
    "train_set = MyDataset(X_train,y_train)\n",
    "test_set = MyDataset(X_test,y_test)\n",
    "train_loader = DataLoader(train_set, batch_size=Batch_Size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=Batch_Size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The neural network architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # 5 linear layers\n",
    "        self.fc1 = nn.Linear(45, 30)\n",
    "        self.fc2 = nn.Linear(30, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "        self.fc4 = nn.Linear(10, 5)\n",
    "        self.fc5 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # a combination of linear layers and relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=45, out_features=30, bias=True)\n",
      "  (fc2): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (fc4): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc5): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizor\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=Lr_Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide to use gpu or cpu\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def training(model, train_loader, Epochs, optimizer_s=optimizer, test_loader = None):\n",
    "    train_loss = []\n",
    "    for epoch in range(Epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            # load data and label\n",
    "            img, label = data\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            optimizer_s.zero_grad()\n",
    "            outputs = model(img)\n",
    "            loss = F.cross_entropy(outputs, label.long()) # nll_loss\n",
    "            # loss  backward\n",
    "            loss.backward()\n",
    "            optimizer_s.step()\n",
    "            running_loss += loss.item()\n",
    "        # compute the overall loss\n",
    "        loss = running_loss / len(train_loader)\n",
    "        train_loss.append(loss)\n",
    "        print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n",
    "            epoch+1, Epochs, loss))\n",
    "        \n",
    "        # compute the test accuracy at last\n",
    "        if (epoch+1) % Epochs == 0:\n",
    "            score, _, _ = test_data(model, test_loader)\n",
    "            print(score)\n",
    "\n",
    "    return model, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "def test_data(model, test_loader):\n",
    "     running_loss = 0.0\n",
    "     correct=0\n",
    "     len_test = 0\n",
    "     pred_result = []\n",
    "     label_org = []\n",
    "     ii = 0\n",
    "     for data in test_loader:\n",
    "        # load the data\n",
    "        img, label = data\n",
    "        label=label.long()\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img)\n",
    "        loss = F.cross_entropy(outputs, label.long()) # nll_loss\n",
    "        outputs = F.softmax(outputs)\n",
    "        outputs = outputs.argmax(dim=1)\n",
    "        # save the results \n",
    "        pred_result.extend(outputs.cpu())\n",
    "        label_org.extend(label.cpu())\n",
    "        correct += balanced_accuracy_score(label.cpu(), outputs.cpu()) \n",
    "        running_loss += loss.item()\n",
    "        len_test += len(img)\n",
    "        ii += 1\n",
    "     loss = running_loss / len(test_loader)\n",
    "     # compute the balanced_accuracy_score \n",
    "     acc = balanced_accuracy_score(label_org, pred_result) \n",
    "     print(accuracy_score(label_org, pred_result), acc)\n",
    "     return acc, label_org, pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=45, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (fc4): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (fc5): Linear(in_features=5, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the device\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample the data using SMOTENC\n",
    "oversample = SMOTENC (categorical_features=[2,4,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "                                                21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,\n",
    "                                                38,39,40,41,42,43,44], random_state=42)\n",
    "X_train_fold_upsample, y_train_fold_upsample = oversample.fit_resample(X_train,y_train)\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "#Fit on training set\n",
    "scaler.fit(X_train_fold_upsample)\n",
    "#scale on training set\n",
    "X_train_fold_upsample = scaler.transform(X_train_fold_upsample)\n",
    "#scale the validation dataset\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset and the dataloader\n",
    "train_set_upsample = MyDataset(X_train_fold_upsample, y_train_fold_upsample)\n",
    "train_loader_upsample = DataLoader(train_set_upsample, batch_size=Batch_Size, shuffle=True)\n",
    "test_set = MyDataset(X_test,y_test)\n",
    "test_loader = DataLoader(test_set, batch_size=Batch_Size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20, Train Loss: 0.447\n",
      "Epoch 2 of 20, Train Loss: 0.392\n",
      "Epoch 3 of 20, Train Loss: 0.385\n",
      "Epoch 4 of 20, Train Loss: 0.381\n",
      "Epoch 5 of 20, Train Loss: 0.379\n",
      "Epoch 6 of 20, Train Loss: 0.378\n",
      "Epoch 7 of 20, Train Loss: 0.375\n",
      "Epoch 8 of 20, Train Loss: 0.375\n",
      "Epoch 9 of 20, Train Loss: 0.373\n",
      "Epoch 10 of 20, Train Loss: 0.372\n",
      "Epoch 11 of 20, Train Loss: 0.371\n",
      "Epoch 12 of 20, Train Loss: 0.371\n",
      "Epoch 13 of 20, Train Loss: 0.370\n",
      "Epoch 14 of 20, Train Loss: 0.371\n",
      "Epoch 15 of 20, Train Loss: 0.370\n",
      "Epoch 16 of 20, Train Loss: 0.368\n",
      "Epoch 17 of 20, Train Loss: 0.368\n",
      "Epoch 18 of 20, Train Loss: 0.369\n",
      "Epoch 19 of 20, Train Loss: 0.367\n",
      "Epoch 20 of 20, Train Loss: 0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7931684487633657 0.7172816248557129\n",
      "0.7172816248557129\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "model, train_loss = training(model, train_loader_upsample, Epochs = Epochs,  optimizer_s=optimizer, test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7931684487633657 0.7172816248557129\n"
     ]
    }
   ],
   "source": [
    "# compute the score (vanilla accuracy and balanced accuracy on test)\n",
    "score, y_test, pred = test_data(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7172816248557129"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8367720135161996\n",
      "Precision: 0.9031192345647231\n",
      "F1: 0.8686806157401676\n"
     ]
    }
   ],
   "source": [
    "# compute Recall, Precision and F1 for class 1\n",
    "recall_open = recall_score(y_test, pred, pos_label=1)\n",
    "precision_open = precision_score(y_test, pred, pos_label=1)\n",
    "f1_open = f1_score(y_test, pred, pos_label=1)\n",
    "\n",
    "print(\"Recall: \" + str(recall_open))\n",
    "print(\"Precision: \" + str(precision_open))\n",
    "print(\"F1: \" + str(f1_open))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5977912361952262\n",
      "Precision: 0.44974537657464486\n",
      "F1: 0.5133068216579993\n"
     ]
    }
   ],
   "source": [
    "# compute Recall, Precision and F1 for class 0\n",
    "recall_closed = recall_score(y_test, pred, pos_label=0)\n",
    "precision_closed = precision_score(y_test, pred, pos_label=0)\n",
    "f1_closed = f1_score(y_test, pred, pos_label=0)\n",
    "\n",
    "print(\"Recall: \" + str(recall_closed))\n",
    "print(\"Precision: \" + str(precision_closed))\n",
    "print(\"F1: \" + str(f1_closed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "# use SMOTE to conduct the cross validation\n",
    "def score_model(model, cv, X_train, y_train, Epochs = 100):\n",
    "    \"\"\"\n",
    "    Creates folds manually, and upsamples within each fold.\n",
    "    Returns an array of validation (recall) scores\n",
    "    \"\"\"\n",
    "    oversample = SMOTENC (categorical_features=[2,4,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "                                                21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,\n",
    "                                                38,39,40,41,42,43,44], random_state=42)\n",
    "\n",
    "    if cv is None:\n",
    "        cv = KFold(n_splits=5, random_state=42)\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    for train_fold_index, val_fold_index in cv.split(X_train, y_train):\n",
    "        # Get the training data\n",
    "        print('start...')\n",
    "        X_train_fold, y_train_fold = X_train[train_fold_index], y_train[train_fold_index]\n",
    "        # Get the validation data\n",
    "        X_val_fold, y_val_fold = X_train[val_fold_index], y_train[val_fold_index]\n",
    "\n",
    "        # Upsample only the data in the training section\n",
    "        X_train_fold_upsample, y_train_fold_upsample = oversample.fit_resample(X_train_fold,y_train_fold)\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        #Fit on training set\n",
    "        scaler.fit(X_train_fold_upsample)\n",
    "        #scale on training set\n",
    "        X_train_fold_upsample = scaler.transform(X_train_fold_upsample)\n",
    "        #scale the validation dataset\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "        # Build the datset and dataloader\n",
    "        train_set = MyDataset(X_train_fold_upsample,y_train_fold_upsample)\n",
    "        test_set = MyDataset(X_val_fold,y_val_fold)\n",
    "        train_loader = DataLoader(train_set, batch_size=Batch_Size, shuffle=True)\n",
    "        test_loader = DataLoader(test_set, batch_size=Batch_Size, shuffle=True)\n",
    "        print('training...')\n",
    "        # Build the model and optimizor\n",
    "        model = MLP()\n",
    "        device = get_device()\n",
    "        model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=Lr_Rate)\n",
    "        # training \n",
    "        model_save, _ = training(model, train_loader, Epochs,  optimizer_s=optimizer, test_loader = test_loader)\n",
    "        # Score the model on the (non-upsampled) validation data\n",
    "        # test the score\n",
    "        score, label_org, pred_result = test_data(model_save, test_loader)\n",
    "        scores.append(score)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.439\n",
      "Epoch 2 of 20, Train Loss: 0.391\n",
      "Epoch 3 of 20, Train Loss: 0.384\n",
      "Epoch 4 of 20, Train Loss: 0.380\n",
      "Epoch 5 of 20, Train Loss: 0.378\n",
      "Epoch 6 of 20, Train Loss: 0.375\n",
      "Epoch 7 of 20, Train Loss: 0.373\n",
      "Epoch 8 of 20, Train Loss: 0.372\n",
      "Epoch 9 of 20, Train Loss: 0.371\n",
      "Epoch 10 of 20, Train Loss: 0.370\n",
      "Epoch 11 of 20, Train Loss: 0.369\n",
      "Epoch 12 of 20, Train Loss: 0.368\n",
      "Epoch 13 of 20, Train Loss: 0.368\n",
      "Epoch 14 of 20, Train Loss: 0.366\n",
      "Epoch 15 of 20, Train Loss: 0.366\n",
      "Epoch 16 of 20, Train Loss: 0.365\n",
      "Epoch 17 of 20, Train Loss: 0.364\n",
      "Epoch 18 of 20, Train Loss: 0.364\n",
      "Epoch 19 of 20, Train Loss: 0.363\n",
      "Epoch 20 of 20, Train Loss: 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7789242768930776 0.7166998237200165\n",
      "0.7166998237200165\n",
      "0.7789242768930776 0.7166998237200165\n",
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.453\n",
      "Epoch 2 of 20, Train Loss: 0.389\n",
      "Epoch 3 of 20, Train Loss: 0.381\n",
      "Epoch 4 of 20, Train Loss: 0.377\n",
      "Epoch 5 of 20, Train Loss: 0.374\n",
      "Epoch 6 of 20, Train Loss: 0.373\n",
      "Epoch 7 of 20, Train Loss: 0.373\n",
      "Epoch 8 of 20, Train Loss: 0.370\n",
      "Epoch 9 of 20, Train Loss: 0.369\n",
      "Epoch 10 of 20, Train Loss: 0.368\n",
      "Epoch 11 of 20, Train Loss: 0.366\n",
      "Epoch 12 of 20, Train Loss: 0.366\n",
      "Epoch 13 of 20, Train Loss: 0.365\n",
      "Epoch 14 of 20, Train Loss: 0.364\n",
      "Epoch 15 of 20, Train Loss: 0.363\n",
      "Epoch 16 of 20, Train Loss: 0.362\n",
      "Epoch 17 of 20, Train Loss: 0.363\n",
      "Epoch 18 of 20, Train Loss: 0.361\n",
      "Epoch 19 of 20, Train Loss: 0.360\n",
      "Epoch 20 of 20, Train Loss: 0.360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7799805004874878 0.6976160090218675\n",
      "0.6976160090218675\n",
      "0.7799805004874878 0.6976160090218675\n",
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.429\n",
      "Epoch 2 of 20, Train Loss: 0.384\n",
      "Epoch 3 of 20, Train Loss: 0.377\n",
      "Epoch 4 of 20, Train Loss: 0.373\n",
      "Epoch 5 of 20, Train Loss: 0.371\n",
      "Epoch 6 of 20, Train Loss: 0.370\n",
      "Epoch 7 of 20, Train Loss: 0.369\n",
      "Epoch 8 of 20, Train Loss: 0.367\n",
      "Epoch 9 of 20, Train Loss: 0.367\n",
      "Epoch 10 of 20, Train Loss: 0.366\n",
      "Epoch 11 of 20, Train Loss: 0.365\n",
      "Epoch 12 of 20, Train Loss: 0.365\n",
      "Epoch 13 of 20, Train Loss: 0.364\n",
      "Epoch 14 of 20, Train Loss: 0.363\n",
      "Epoch 15 of 20, Train Loss: 0.362\n",
      "Epoch 16 of 20, Train Loss: 0.361\n",
      "Epoch 17 of 20, Train Loss: 0.361\n",
      "Epoch 18 of 20, Train Loss: 0.360\n",
      "Epoch 19 of 20, Train Loss: 0.360\n",
      "Epoch 20 of 20, Train Loss: 0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8065485862853429 0.704925654511724\n",
      "0.704925654511724\n",
      "0.8065485862853429 0.704925654511724\n",
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.432\n",
      "Epoch 2 of 20, Train Loss: 0.387\n",
      "Epoch 3 of 20, Train Loss: 0.382\n",
      "Epoch 4 of 20, Train Loss: 0.378\n",
      "Epoch 5 of 20, Train Loss: 0.376\n",
      "Epoch 6 of 20, Train Loss: 0.374\n",
      "Epoch 7 of 20, Train Loss: 0.373\n",
      "Epoch 8 of 20, Train Loss: 0.372\n",
      "Epoch 9 of 20, Train Loss: 0.371\n",
      "Epoch 10 of 20, Train Loss: 0.370\n",
      "Epoch 11 of 20, Train Loss: 0.369\n",
      "Epoch 12 of 20, Train Loss: 0.369\n",
      "Epoch 13 of 20, Train Loss: 0.368\n",
      "Epoch 14 of 20, Train Loss: 0.367\n",
      "Epoch 15 of 20, Train Loss: 0.366\n",
      "Epoch 16 of 20, Train Loss: 0.367\n",
      "Epoch 17 of 20, Train Loss: 0.366\n",
      "Epoch 18 of 20, Train Loss: 0.365\n",
      "Epoch 19 of 20, Train Loss: 0.365\n",
      "Epoch 20 of 20, Train Loss: 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8170295742606435 0.7102011599295852\n",
      "0.7102011599295852\n",
      "0.8170295742606435 0.7102011599295852\n",
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.448\n",
      "Epoch 2 of 20, Train Loss: 0.390\n",
      "Epoch 3 of 20, Train Loss: 0.381\n",
      "Epoch 4 of 20, Train Loss: 0.379\n",
      "Epoch 5 of 20, Train Loss: 0.374\n",
      "Epoch 6 of 20, Train Loss: 0.373\n",
      "Epoch 7 of 20, Train Loss: 0.372\n",
      "Epoch 8 of 20, Train Loss: 0.372\n",
      "Epoch 9 of 20, Train Loss: 0.369\n",
      "Epoch 10 of 20, Train Loss: 0.370\n",
      "Epoch 11 of 20, Train Loss: 0.369\n",
      "Epoch 12 of 20, Train Loss: 0.368\n",
      "Epoch 13 of 20, Train Loss: 0.367\n",
      "Epoch 14 of 20, Train Loss: 0.367\n",
      "Epoch 15 of 20, Train Loss: 0.366\n",
      "Epoch 16 of 20, Train Loss: 0.366\n",
      "Epoch 17 of 20, Train Loss: 0.365\n",
      "Epoch 18 of 20, Train Loss: 0.364\n",
      "Epoch 19 of 20, Train Loss: 0.363\n",
      "Epoch 20 of 20, Train Loss: 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788981880230763 0.7149485840872705\n",
      "0.7149485840872705\n",
      "0.788981880230763 0.7149485840872705\n",
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.427\n",
      "Epoch 2 of 20, Train Loss: 0.388\n",
      "Epoch 3 of 20, Train Loss: 0.382\n",
      "Epoch 4 of 20, Train Loss: 0.379\n",
      "Epoch 5 of 20, Train Loss: 0.377\n",
      "Epoch 6 of 20, Train Loss: 0.374\n",
      "Epoch 7 of 20, Train Loss: 0.373\n",
      "Epoch 8 of 20, Train Loss: 0.371\n",
      "Epoch 9 of 20, Train Loss: 0.370\n",
      "Epoch 10 of 20, Train Loss: 0.369\n",
      "Epoch 11 of 20, Train Loss: 0.368\n",
      "Epoch 12 of 20, Train Loss: 0.368\n",
      "Epoch 13 of 20, Train Loss: 0.367\n",
      "Epoch 14 of 20, Train Loss: 0.367\n",
      "Epoch 15 of 20, Train Loss: 0.366\n",
      "Epoch 16 of 20, Train Loss: 0.366\n",
      "Epoch 17 of 20, Train Loss: 0.365\n",
      "Epoch 18 of 20, Train Loss: 0.365\n",
      "Epoch 19 of 20, Train Loss: 0.364\n",
      "Epoch 20 of 20, Train Loss: 0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801413829527911 0.7191622477206228\n",
      "0.7191622477206228\n",
      "0.801413829527911 0.7191622477206228\n",
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.423\n",
      "Epoch 2 of 20, Train Loss: 0.387\n",
      "Epoch 3 of 20, Train Loss: 0.382\n",
      "Epoch 4 of 20, Train Loss: 0.377\n",
      "Epoch 5 of 20, Train Loss: 0.374\n",
      "Epoch 6 of 20, Train Loss: 0.372\n",
      "Epoch 7 of 20, Train Loss: 0.370\n",
      "Epoch 8 of 20, Train Loss: 0.368\n",
      "Epoch 9 of 20, Train Loss: 0.367\n",
      "Epoch 10 of 20, Train Loss: 0.366\n",
      "Epoch 11 of 20, Train Loss: 0.365\n",
      "Epoch 12 of 20, Train Loss: 0.365\n",
      "Epoch 13 of 20, Train Loss: 0.364\n",
      "Epoch 14 of 20, Train Loss: 0.363\n",
      "Epoch 15 of 20, Train Loss: 0.362\n",
      "Epoch 16 of 20, Train Loss: 0.361\n",
      "Epoch 17 of 20, Train Loss: 0.361\n",
      "Epoch 18 of 20, Train Loss: 0.361\n",
      "Epoch 19 of 20, Train Loss: 0.359\n",
      "Epoch 20 of 20, Train Loss: 0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7972698464288617 0.7013958268476534\n",
      "0.7013958268476534\n",
      "0.7972698464288617 0.7013958268476534\n",
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.467\n",
      "Epoch 2 of 20, Train Loss: 0.388\n",
      "Epoch 3 of 20, Train Loss: 0.380\n",
      "Epoch 4 of 20, Train Loss: 0.376\n",
      "Epoch 5 of 20, Train Loss: 0.375\n",
      "Epoch 6 of 20, Train Loss: 0.372\n",
      "Epoch 7 of 20, Train Loss: 0.372\n",
      "Epoch 8 of 20, Train Loss: 0.371\n",
      "Epoch 9 of 20, Train Loss: 0.369\n",
      "Epoch 10 of 20, Train Loss: 0.368\n",
      "Epoch 11 of 20, Train Loss: 0.368\n",
      "Epoch 12 of 20, Train Loss: 0.367\n",
      "Epoch 13 of 20, Train Loss: 0.366\n",
      "Epoch 14 of 20, Train Loss: 0.365\n",
      "Epoch 15 of 20, Train Loss: 0.365\n",
      "Epoch 16 of 20, Train Loss: 0.364\n",
      "Epoch 17 of 20, Train Loss: 0.365\n",
      "Epoch 18 of 20, Train Loss: 0.364\n",
      "Epoch 19 of 20, Train Loss: 0.364\n",
      "Epoch 20 of 20, Train Loss: 0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797188591858292 0.7163963196507741\n",
      "0.7163963196507741\n",
      "0.797188591858292 0.7163963196507741\n",
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.440\n",
      "Epoch 2 of 20, Train Loss: 0.388\n",
      "Epoch 3 of 20, Train Loss: 0.380\n",
      "Epoch 4 of 20, Train Loss: 0.376\n",
      "Epoch 5 of 20, Train Loss: 0.375\n",
      "Epoch 6 of 20, Train Loss: 0.371\n",
      "Epoch 7 of 20, Train Loss: 0.370\n",
      "Epoch 8 of 20, Train Loss: 0.370\n",
      "Epoch 9 of 20, Train Loss: 0.367\n",
      "Epoch 10 of 20, Train Loss: 0.367\n",
      "Epoch 11 of 20, Train Loss: 0.367\n",
      "Epoch 12 of 20, Train Loss: 0.365\n",
      "Epoch 13 of 20, Train Loss: 0.364\n",
      "Epoch 14 of 20, Train Loss: 0.364\n",
      "Epoch 15 of 20, Train Loss: 0.363\n",
      "Epoch 16 of 20, Train Loss: 0.363\n",
      "Epoch 17 of 20, Train Loss: 0.363\n",
      "Epoch 18 of 20, Train Loss: 0.362\n",
      "Epoch 19 of 20, Train Loss: 0.360\n",
      "Epoch 20 of 20, Train Loss: 0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8026326480864548 0.7222530567904579\n",
      "0.7222530567904579\n",
      "0.8026326480864548 0.7222530567904579\n",
      "start...\n",
      "training...\n",
      "Epoch 1 of 20, Train Loss: 0.425\n",
      "Epoch 2 of 20, Train Loss: 0.385\n",
      "Epoch 3 of 20, Train Loss: 0.379\n",
      "Epoch 4 of 20, Train Loss: 0.375\n",
      "Epoch 5 of 20, Train Loss: 0.374\n",
      "Epoch 6 of 20, Train Loss: 0.372\n",
      "Epoch 7 of 20, Train Loss: 0.371\n",
      "Epoch 8 of 20, Train Loss: 0.370\n",
      "Epoch 9 of 20, Train Loss: 0.369\n",
      "Epoch 10 of 20, Train Loss: 0.368\n",
      "Epoch 11 of 20, Train Loss: 0.368\n",
      "Epoch 12 of 20, Train Loss: 0.368\n",
      "Epoch 13 of 20, Train Loss: 0.366\n",
      "Epoch 14 of 20, Train Loss: 0.365\n",
      "Epoch 15 of 20, Train Loss: 0.366\n",
      "Epoch 16 of 20, Train Loss: 0.364\n",
      "Epoch 17 of 20, Train Loss: 0.364\n",
      "Epoch 18 of 20, Train Loss: 0.364\n",
      "Epoch 19 of 20, Train Loss: 0.362\n",
      "Epoch 20 of 20, Train Loss: 0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7948322093117738 0.7284924653225082\n",
      "0.7284924653225082\n",
      "0.7948322093117738 0.7284924653225082\n"
     ]
    }
   ],
   "source": [
    "# do cross validation\n",
    "cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=20)\n",
    "# get the cross validation results\n",
    "scores = score_model(model, cv, X_train, y_train, Epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7132091147602481"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the cross validation results\n",
    "scores\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
